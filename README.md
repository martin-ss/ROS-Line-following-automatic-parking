# ROS-Line-following-automatic-parking

# Using ROS_TurtleBot3

## Abstract

* Demonstration of Visual Servoing project is developed under ROS environment and using TheConstruct platform with TurtleBot running on Gazebo web version           “Gzweb”.   The main idea of the project is to develop an application running on TurtleBot to solve different navigation problems. This project can 
  be sub-divided into 2  parts, Line following task and Parking task. For each task, control and simulation is achieved through different implementations, which     in order to be solved, a certain skills related to ROS basics and their programming architecture understanding should be mastered .On top of that, 
  Our simulated ROS environment provided by The-Construct website is exploited with different ROS online courses. In this report, a detailed guideline 
  about the implementation will be presented in order to deliver the key features of our approach.


## See DEMO examples:

* <https://drive.google.com/drive/folders/1NVIkTawzJ-T4mepiQFDwKJSvNbRyF0Iy>

## Introduction

*Visual servoing refers to closed loop position control of a robot end-effector, using measurements from a vision sensor as mentioned in [3]. Two kinds of configurations for visual servo control are most frequently encountered in literature:
1-Eye-in-hand
2-Eye-to-hand

  
  
## Pipeline
![alt text](https://github.com/martin-ss/ROS_TurtleBot3/blob/main/Report/FINAL%20REPORT_MARTIN%20EMILE-04.png?raw=true)

## Table of contents

Use for instance <https://github.com/ekalinin/github-markdown-toc>:

> * [Title / Repository Name](#TurtleBot3)
>   * [About / Synopsis](#Abstract)
>   * [Table of contents](#table-of-contents)
>   * [Installation](#installation)
>   * [Usage](#usage)
>     * [Screenshot of the Environment](#screenshot-of-the-Environment)
>     * [Task 1 Steps](#features)
>     * [Task 2 Steps](#features)
>     * [Task 3 Steps](#features)
>     * [Task 4 Steps](#features)
>   * [Refrencess](#Refrencess)


>   * [About the Project](#)


## Installation

Sample:

* From the Crrent repo: git clone  https://github.com/martin-ss/ROS-Line-following-automatic-parking


## Usage

* This project is aimed to control the navigation of TurtleBot3 for line following and automatic parking tasks based on Image based visual servoing
### Screenshot of the Environment

![alt text](https://github.com/martin-ss/ROS_TurtleBot3/blob/main/ros2.png?raw=true)



## Process (Steps)
![alt text](https://github.com/martin-ss/ROS_TurtleBot3/blob/main/Report/FINAL%20REPORT_MARTIN%20EMILE-09.png?raw=true)
![alt text](https://github.com/martin-ss/ROS_TurtleBot3/blob/main/Report/FINAL%20REPORT_MARTIN%20EMILE-10.png?raw=true)
![alt text](https://github.com/martin-ss/ROS_TurtleBot3/blob/main/Report/FINAL%20REPORT_MARTIN%20EMILE-11.png?raw=true)
![alt text](https://github.com/martin-ss/ROS_TurtleBot3/blob/main/Report/FINAL%20REPORT_MARTIN%20EMILE-12.png?raw=true)


## Refrencess

[1] https://emanual.robotis.com/docs/en/platform/turtlebot3/overview/ \
[2] https://www.roscomponents.com/en/mobile-robots/214-turtlebot-3.html#/courses-no \
[3] Book "ROS Robotics Projects" \
[4] http://wiki.ros.org/gmapping \
[5] Course titled “Mastering with ROS: Turtlebot3” \
[6] Course titled “ROS Navigation in 5 days” \
[7] http://wiki.ros.org/ROS/Tutorials/ExaminingPublisherSubscriber \
[8] http://wiki.ros.org/navigation 

## About The Visual servoing Project
It is impelemneted as a part of a course module named visual servoing and tracking for Master-2 
